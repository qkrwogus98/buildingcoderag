"""
ê±´ì¶• ê´€ë ¨ ë²•ë ¹ Graph RAG - Upstage Document Parse API í™œìš© ë²„ì „
=============================================================

ê¸°ì¡´ pdfplumber ëŒ€ì‹  Upstage Document Parse APIë¥¼ ì‚¬ìš©í•˜ì—¬
ë” ì •í™•í•œ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œê³¼ êµ¬ì¡° íŒŒì‹±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

ì§€ì› ë²•ë ¹: ê±´ì¶•ë²•, ê±´ì¶•ë¬¼ê´€ë¦¬ë²•, ì£¼íƒë²•, êµ­í† ê³„íšë²•, ì£¼ì°¨ì¥ë²•, ê±´ì¶•ì„œë¹„ìŠ¤ì‚°ì—…ì§„í¥ë²• ë“±
"""

import os
import re
import json
import logging
import datetime
from dataclasses import dataclass
from typing import List, Dict, Optional
from collections import defaultdict

from neo4j import GraphDatabase

# Upstage ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
# try:
#     from langchain_upstage import UpstageDocumentParseLoader
#     UPSTAGE_LANGCHAIN_AVAILABLE = True
# except ImportError:
UPSTAGE_LANGCHAIN_AVAILABLE = False
print("âš ï¸  langchain_upstage íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. pip install langchain-upstageë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")

import requests  # ì§ì ‘ API í˜¸ì¶œìš© ë°±ì—…


# ==========================================
# ë¡œê±° ì„¤ì •
# ==========================================
def setup_custom_logger():
    """
    ì½˜ì†”ê³¼ íŒŒì¼ ëª¨ë‘ì— ë¡œê·¸ë¥¼ ì¶œë ¥í•˜ëŠ” ë¡œê±° ì„¤ì •
    
    Returns:
        logger: ì„¤ì •ëœ ë¡œê±° ê°ì²´
    """
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ì¶œë ¥ ë°©ì§€)
    if logger.hasHandlers():
        logger.handlers.clear()
        
    formatter = logging.Formatter('%(levelname)s - %(message)s')
    
    # ì½˜ì†” ì¶œë ¥ í•¸ë“¤ëŸ¬
    stream_handler = logging.StreamHandler()
    stream_handler.setFormatter(formatter)
    logger.addHandler(stream_handler)
    
    # íŒŒì¼ ì €ì¥ í•¸ë“¤ëŸ¬
    file_handler = logging.FileHandler('build_graph_log.txt', mode='a', encoding='utf-8')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    
    return logger

logger = setup_custom_logger()


# ==========================================
# ë²•ë ¹ ì •ì˜ (Dataclass)
# ==========================================
@dataclass
class LawDefinition:
    """
    ë²•ë ¹ ì •ì˜ í´ë˜ìŠ¤
    
    Attributes:
        code: ë²•ë ¹ ì½”ë“œ (ì˜ˆ: BUILDING, HOUSING)
        name: ë²•ë ¹ëª… (ì˜ˆ: ê±´ì¶•ë²•, ì£¼íƒë²•)
        act_label: Neo4j ë ˆì´ë¸” - ë²•ë¥ 
        decree_label: Neo4j ë ˆì´ë¸” - ì‹œí–‰ë ¹
        rule_label: Neo4j ë ˆì´ë¸” - ì‹œí–‰ê·œì¹™
        pdf_paths: PDF íŒŒì¼ ê²½ë¡œ ë”•ì…”ë„ˆë¦¬
    """
    code: str
    name: str
    act_label: str
    decree_label: str
    rule_label: str
    pdf_paths: Dict[str, str]


# ì§€ì›í•˜ëŠ” ë²•ë ¹ ëª©ë¡
LAWS = {
    'BUILDING': LawDefinition(
        code='BUILDING',
        name='ê±´ì¶•ë²•',
        act_label='BuildingAct',
        decree_label='BuildingDecree',
        rule_label='BuildingRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/ê±´ì¶•ë²•(ë²•ë¥ )(ì œ21065í˜¸)(20251001).pdf',
            'Decree': '/home/jaehyeonpark/Downloads/ê±´ì¶•ë²• ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ35811í˜¸)(20251001).pdf',
            'Rule': '/home/jaehyeonpark/Downloads/ê±´ì¶•ë²• ì‹œí–‰ê·œì¹™(êµ­í† êµí†µë¶€ë ¹)(ì œ01531í˜¸)(20251031).pdf'
        }
    ),
    'BUILDING_MGMT': LawDefinition(
        code='BUILDING_MGMT',
        name='ê±´ì¶•ë¬¼ê´€ë¦¬ë²•',
        act_label='BuildingMgmtAct',
        decree_label='BuildingMgmtDecree',
        rule_label='BuildingMgmtRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/ê±´ì¶•ë¬¼ê´€ë¦¬ë²•(ë²•ë¥ )(ì œ20549í˜¸)(20250604).pdf',
            'Decree': '/home/jaehyeonpark/Downloads/ê±´ì¶•ë¬¼ê´€ë¦¬ë²• ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ35549í˜¸)(20250604).pdf',
            'Rule': '/home/jaehyeonpark/Downloads/ê±´ì¶•ë¬¼ê´€ë¦¬ë²• ì‹œí–‰ê·œì¹™(êµ­í† êµí†µë¶€ë ¹)(ì œ01495í˜¸)(20250602).pdf'
        }
    ),
    'BUILDING_SERVICE': LawDefinition(
        code='BUILDING_SERVICE',
        name='ê±´ì¶•ì„œë¹„ìŠ¤ì‚°ì—…ì§„í¥ë²•',
        act_label='BuildingServiceAct',
        decree_label='BuildingServiceDecree',
        rule_label='BuildingServiceRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/ê±´ì¶•ì„œë¹„ìŠ¤ì‚°ì—… ì§„í¥ë²•(ë²•ë¥ )(ì œ19990í˜¸)(20240710).pdf',
            'Decree': '/home/jaehyeonpark/Downloads/ê±´ì¶•ì„œë¹„ìŠ¤ì‚°ì—… ì§„í¥ë²• ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ33466í˜¸)(20230516).pdf',
            'Rule': '/home/jaehyeonpark/Downloads/ê±´ì¶•ì„œë¹„ìŠ¤ì‚°ì—… ì§„í¥ë²• ì‹œí–‰ê·œì¹™(êµ­í† êµí†µë¶€ë ¹)(ì œ00098í˜¸)(20140605).pdf'
        }
    ),
    'PARKING': LawDefinition(
        code='PARKING',
        name='ì£¼ì°¨ì¥ë²•',
        act_label='ParkingAct',
        decree_label='ParkingDecree',
        rule_label='ParkingRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/ì£¼ì°¨ì¥ë²•(ë²•ë¥ )(ì œ21185í˜¸)(20251202).pdf',
            'Decree': '/home/jaehyeonpark/Downloads/ì£¼ì°¨ì¥ë²• ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ35708í˜¸)(20250817).pdf',
            'Rule': '/home/jaehyeonpark/Downloads/ì£¼ì°¨ì¥ë²• ì‹œí–‰ê·œì¹™(êµ­í† êµí†µë¶€ë ¹)(ì œ01527í˜¸)(20250930).pdf'
        }
    ),
    'LAND_PLAN': LawDefinition(
        code='LAND_PLAN',
        name='êµ­í† ì˜ê³„íšë°ì´ìš©ì—ê´€í•œë²•ë¥ ',
        act_label='LandPlanAct',
        decree_label='LandPlanDecree',
        rule_label='LandPlanRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/êµ­í† ì˜ ê³„íš ë° ì´ìš©ì— ê´€í•œ ë²•ë¥ (ë²•ë¥ )(ì œ21065í˜¸)(20251001).pdf',
            'Decree': '/home/jaehyeonpark/Downloads/êµ­í† ì˜ ê³„íš ë° ì´ìš©ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ35628í˜¸)(20251002).pdf',
            'Rule': '/home/jaehyeonpark/Downloads/êµ­í† ì˜ ê³„íš ë° ì´ìš©ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ê·œì¹™(êµ­í† êµí†µë¶€ë ¹)(ì œ01338í˜¸)(20241130).pdf'
        }
    ),
    'HOUSING': LawDefinition(
        code='HOUSING',
        name='ì£¼íƒë²•',
        act_label='HousingAct',
        decree_label='HousingDecree',
        rule_label='HousingRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/ì£¼íƒë²•.pdf',
            'Decree': '/home/jaehyeonpark/Downloads/ì£¼íƒë²• ì‹œí–‰ë ¹.pdf',
            'Rule': '/home/jaehyeonpark/Downloads/ì£¼íƒë²• ì‹œí–‰ê·œì¹™.pdf'
        }
    ),
    'GREEN_BUILDING': LawDefinition(
        code='GREEN_BUILDING',
        name='ë…¹ìƒ‰ê±´ì¶•ë¬¼ì¡°ì„±ì§€ì›ë²•',
        act_label='GreenBuildingAct',
        decree_label='GreenBuildingDecree',
        rule_label='GreenBuildingRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›ë²•(ë²•ë¥ )(ì œ21065í˜¸)(20251001).pdf',
            'Decree': '/home/jaehyeonpark/Downloads/ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›ë²• ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ35811í˜¸)(20251001).pdf',
            'Rule': '/home/jaehyeonpark/Downloads/ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›ë²• ì‹œí–‰ê·œì¹™(êµ­í† êµí†µë¶€ë ¹)(ì œ01422í˜¸)(20250101).pdf'
        }
    ),
    'HANOK': LawDefinition(
        code='HANOK',
        name='í•œì˜¥ë“±ê±´ì¶•ìì‚°ì˜ì§„í¥ì—ê´€í•œë²•ë¥ ',
        act_label='HanokAct',
        decree_label='HanokDecree',
        rule_label='HanokRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/í•œì˜¥ ë“± ê±´ì¶•ìì‚°ì˜ ì§„í¥ì— ê´€í•œ ë²•ë¥ (ë²•ë¥ )(ì œ19702í˜¸)(20240915).pdf',
            'Decree': '/home/jaehyeonpark/Downloads/í•œì˜¥ ë“± ê±´ì¶•ìì‚°ì˜ ì§„í¥ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ34494í˜¸)(20240517).pdf',
            'Rule': '/home/jaehyeonpark/Downloads/í•œì˜¥ ë“± ê±´ì¶•ìì‚°ì˜ ì§„í¥ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ê·œì¹™(êµ­í† êµí†µë¶€ë ¹)(ì œ00882í˜¸)(20210827).pdf'
        }
    ),
    'BUILDING_SALE': LawDefinition(
        code='BUILDING_SALE',
        name='ê±´ì¶•ë¬¼ì˜ë¶„ì–‘ì—ê´€í•œë²•ë¥ ',
        act_label='BuildingSaleAct',
        decree_label='BuildingSaleDecree',
        rule_label='BuildingSaleRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/í•œì˜¥ ë“± ê±´ì¶•ìì‚°ì˜ ì§„í¥ì— ê´€í•œ ë²•ë¥ (ë²•ë¥ )(ì œ19702í˜¸)(20240915).pdf',
            'Decree': '/home/jaehyeonpark/Downloads/í•œì˜¥ ë“± ê±´ì¶•ìì‚°ì˜ ì§„í¥ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ34494í˜¸)(20240517).pdf',
            'Rule': '/home/jaehyeonpark/Downloads/í•œì˜¥ ë“± ê±´ì¶•ìì‚°ì˜ ì§„í¥ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ê·œì¹™(êµ­í† êµí†µë¶€ë ¹)(ì œ00882í˜¸)(20210827).pdf'
        }
    ),
    'CONVENIENCE': LawDefinition(
        code='CONVENIENCE',
        name='ì¥ì• ì¸ë…¸ì¸ì„ì‚°ë¶€ë“±ì˜í¸ì˜ì¦ì§„ë³´ì¥ì—ê´€í•œë²•ë¥ ',
        act_label='ConvenienceAct',
        decree_label='ConvenienceDecree',
        rule_label='ConvenienceRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/ì¥ì• ì¸ã†ë…¸ì¸ã†ì„ì‚°ë¶€ ë“±ì˜ í¸ì˜ì¦ì§„ ë³´ì¥ì— ê´€í•œ ë²•ë¥ (ë²•ë¥ )(ì œ20594í˜¸)(20251221).pdf',
            'Decree': '/home/jaehyeonpark/Downloads/ì¥ì• ì¸ã†ë…¸ì¸ã†ì„ì‚°ë¶€ ë“±ì˜ í¸ì˜ì¦ì§„ ë³´ì¥ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ35811í˜¸)(20251001).pdf',
            'Rule': '/home/jaehyeonpark/Downloads/ì¥ì• ì¸ã†ë…¸ì¸ã†ì„ì‚°ë¶€ ë“±ì˜ í¸ì˜ì¦ì§„ ë³´ì¥ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ê·œì¹™(ë³´ê±´ë³µì§€ë¶€ë ¹)(ì œ01139í˜¸)(20251221).pdf'
        }
    ),
}


# ==========================================
# Upstage APIë¥¼ ì‚¬ìš©í•œ PDF ì¶”ì¶œê¸°
# ==========================================
class UpstageDocumentExtractor:
    """
    Upstage Document Parse APIë¥¼ ì‚¬ìš©í•˜ì—¬ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í´ë˜ìŠ¤
    
    langchain_upstage íŒ¨í‚¤ì§€ë¥¼ ìš°ì„  ì‚¬ìš©í•˜ê³ ,
    ì—†ìœ¼ë©´ requestsë¡œ ì§ì ‘ API í˜¸ì¶œí•©ë‹ˆë‹¤.
    """
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Upstage ì¶”ì¶œê¸° ì´ˆê¸°í™”
        
        Args:
            api_key: Upstage API í‚¤. ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´
        """
        # API í‚¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ ìš°ì„ )
        self.api_key = api_key or os.getenv("UPSTAGE_API_KEY")
        if not self.api_key:
            raise ValueError("UPSTAGE_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ api_keyë¥¼ ì „ë‹¬í•´ì£¼ì„¸ìš”.")
        
        # API ì—”ë“œí¬ì¸íŠ¸
        self.api_url = "https://api.upstage.ai/v1/document-ai/document-parse"
        
        logger.info("âœ… Upstage Document Extractor ì´ˆê¸°í™” ì™„ë£Œ")
    
    def extract_with_langchain(self, pdf_path: str) -> str:
        """
        langchain_upstageë¥¼ ì‚¬ìš©í•˜ì—¬ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì „ì²´
        """
        if not UPSTAGE_LANGCHAIN_AVAILABLE:
            raise ImportError("langchain_upstage íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        logger.info(f"ğŸ“„ [LangChain] {os.path.basename(pdf_path)} íŒŒì‹± ì¤‘...")
        
        # UpstageDocumentParseLoader ì‚¬ìš©
        loader = UpstageDocumentParseLoader(
            file_path=pdf_path,
            split="page",           # í˜ì´ì§€ë³„ ë¶„ë¦¬
            output_format="html",   # HTML í˜•ì‹ ì¶œë ¥
            ocr="auto"              # PDFëŠ” í…ìŠ¤íŠ¸ ìš°ì„ , ì´ë¯¸ì§€ëŠ” OCR
        )
        
        # ë¬¸ì„œ ë¡œë“œ (lazy_loadë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ ê°œì„ )
        docs = []
        for doc in loader.lazy_load():
            docs.append(doc)
        
        # ëª¨ë“  í˜ì´ì§€ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
        full_text = "\n\n".join([doc.page_content for doc in docs])
        
        # ë…¸ì´ì¦ˆ ì œê±° (ë²•ì œì²˜, êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° ë“±)
        full_text = self._clean_text(full_text)
        
        logger.info(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {len(full_text):,}ì ({len(docs)}í˜ì´ì§€)")
        return full_text
    
    def extract_with_api(self, pdf_path: str) -> str:
        """
        Upstage APIë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë°±ì—… ë©”ì„œë“œ)
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì „ì²´
        """
        logger.info(f"ğŸ“„ [API ì§ì ‘í˜¸ì¶œ] {os.path.basename(pdf_path)} íŒŒì‹± ì¤‘...")
        
        headers = {
            "Authorization": f"Bearer {self.api_key}"
        }
        
        # íŒŒì¼ ì—…ë¡œë“œ
        with open(pdf_path, "rb") as f:
            files = {
                "document": (os.path.basename(pdf_path), f, "application/pdf")
            }
            data = {
                "output_formats": '["text"]',  # í…ìŠ¤íŠ¸ í˜•ì‹ ì¶œë ¥
                "ocr": "auto"
            }
            
            response = requests.post(
                self.api_url,
                headers=headers,
                files=files,
                data=data
            )
        
        if response.status_code != 200:
            logger.error(f"âŒ API ì˜¤ë¥˜: {response.status_code} - {response.text}")
            return ""
        
        result = response.json()
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        full_text = result.get("content", {}).get("text", "")
        
        # ë…¸ì´ì¦ˆ ì œê±°
        full_text = self._clean_text(full_text)
        
        logger.info(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {len(full_text):,}ì")
        return full_text
    
    def extract(self, pdf_path: str) -> str:
        """
        PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìë™ìœ¼ë¡œ ìµœì ì˜ ë°©ë²• ì„ íƒ)
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸
        """
        if not os.path.exists(pdf_path):
            logger.warning(f"âš ï¸  íŒŒì¼ ì—†ìŒ: {pdf_path}")
            return ""
        
        # langchain_upstage ìš°ì„  ì‚¬ìš©
        if UPSTAGE_LANGCHAIN_AVAILABLE:
            try:
                return self.extract_with_langchain(pdf_path)
            except Exception as e:
                logger.warning(f"âš ï¸  LangChain ì‹¤íŒ¨, API ì§ì ‘ í˜¸ì¶œë¡œ ì „í™˜: {e}")
        
        # ë°±ì—…: ì§ì ‘ API í˜¸ì¶œ
        try:
            return self.extract_with_api(pdf_path)
        except Exception as e:
            logger.error(f"âŒ PDF ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    def _clean_text(self, text: str) -> str:
        """
        í…ìŠ¤íŠ¸ì—ì„œ ë…¸ì´ì¦ˆ ì œê±°
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            
        Returns:
            ì •ë¦¬ëœ í…ìŠ¤íŠ¸
        """
        lines = []
        for line in text.split('\n'):
            line = line.strip()
            
            # ë…¸ì´ì¦ˆ íŒ¨í„´ ì œê±°
            if line in ["ë²•ì œì²˜", "êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°"]:
                continue
            if line.endswith("ë²•") and len(line) <= 10:
                continue
            if line.isdigit():
                continue
            if re.match(r'^ë²•ì œì²˜\s+\d+', line):
                continue
            if re.match(r'^\d+\s*/\s*\d+$', line):  # í˜ì´ì§€ ë²ˆí˜¸ (ì˜ˆ: 1 / 100)
                continue
                
            lines.append(line)
        
        return '\n'.join(lines)


# ==========================================
# ë²•ë ¹ íŒŒì„œ
# ==========================================
class LawParser:
    """
    ì¶”ì¶œëœ ë²•ë ¹ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤
    
    ì¡°(Article) > í•­(Clause) > í˜¸(Item) > ëª©(Subitem) êµ¬ì¡°ë¡œ íŒŒì‹±
    """
    
    def parse(self, text: str, law_code: str, law_type: str) -> Dict:
        """
        ë²•ë ¹ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”
        
        Args:
            text: PDFì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸
            law_code: ë²•ë ¹ ì½”ë“œ (ì˜ˆ: BUILDING)
            law_type: ë²•ë ¹ ì¢…ë¥˜ (Act, Decree, Rule)
            
        Returns:
            íŒŒì‹±ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        articles_data = []
        
        # ì¡°í•­ íŒ¨í„´: "ì œNì¡°(ì œëª©)" ë˜ëŠ” "ì œNì¡°ì˜N(ì œëª©)"
        pattern = re.compile(r'\n(ì œ\d+ì¡°(?:ì˜\d+)?)\(([^)]+)\)')
        matches = list(pattern.finditer(text))
        
        for i, match in enumerate(matches):
            article_id = match.group(1)      # ì˜ˆ: ì œ1ì¡°, ì œ2ì¡°ì˜2
            title = match.group(2)            # ì˜ˆ: ëª©ì , ì •ì˜
            
            # ì¡°í•­ í…ìŠ¤íŠ¸ ë²”ìœ„ ê²°ì •
            start = match.start()
            end = matches[i+1].start() if i+1 < len(matches) else len(text)
            article_text = text[start:end].strip()
            
            # í•­(Clause) íŒŒì‹±
            clauses = self._parse_clauses(article_text)
            # ìœ íš¨í•œ ì¡°í•­ë§Œ ì¶”ê°€ (ìµœì†Œ ë‚´ìš© ìˆê±°ë‚˜ í•­ì´ ìˆëŠ” ê²½ìš°)
            if clauses or len(article_text) > 20:
                articles_data.append({
                    'id': article_id,
                    'title': title,
                    'text': article_text,
                    'clauses': clauses
                })
        
        # ì¤‘ë³µ ì œê±° (ë™ì¼ ì¡°í•­ IDê°€ ì—¬ëŸ¬ ë²ˆ ë‚˜ì˜¤ë©´ ê¸´ í…ìŠ¤íŠ¸ ìš°ì„ )
        unique = {}
        for art in articles_data:
            aid = art['id']
            if aid not in unique or len(art['text']) > len(unique[aid]['text']):
                unique[aid] = art
        
        result = list(unique.values())
        logger.info(f"âœ… íŒŒì‹± ì™„ë£Œ - {law_code}/{law_type}: {len(result)}ê°œ ì¡°í•­")
        
        return {
            'law_code': law_code,
            'law_type': law_type,
            'articles': result
        }
    
    def _parse_clauses(self, text: str) -> List[Dict]:
        """
        ì¡°í•­ ë‚´ì—ì„œ í•­(â‘ â‘¡â‘¢...) íŒŒì‹±
        
        Args:
            text: ì¡°í•­ í…ìŠ¤íŠ¸
            
        Returns:
            í•­ ëª©ë¡
        """
        clauses = []
        # ì›ë¬¸ì ìˆ«ìë¡œ í•­ ë¶„ë¦¬
        clause_markers = 'â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©â‘ªâ‘«â‘¬â‘­â‘®â‘¯â‘°â‘±â‘²â‘³'
        parts = re.split(f'([{clause_markers}])', text)
        
        i = 0
        while i < len(parts):
            part = parts[i]
            if part in clause_markers:
                if i + 1 < len(parts):
                    clause_text = parts[i+1].strip()
                    if clause_text:
                        # í˜¸(Item) íŒŒì‹±
                        items = self._parse_items(clause_text)
                        clauses.append({
                            'id': part,
                            'text': clause_text,
                            'items': items
                        })
                i += 2
            else:
                i += 1
        
        return clauses
    
    def _parse_items(self, text: str) -> List[Dict]:
        """
        í•­ ë‚´ì—ì„œ í˜¸(1. 2. 3. ...) íŒŒì‹±
        
        Args:
            text: í•­ í…ìŠ¤íŠ¸
            
        Returns:
            í˜¸ ëª©ë¡
        """
        items = []
        lines = text.split('\n')
        current_item = None
        current_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # í˜¸ íŒ¨í„´: "N. " (ìˆ«ì + ë§ˆì¹¨í‘œ + ê³µë°±)
            match = re.match(r'^(\d+)\.\s', line)
            if match:
                # ì´ì „ í˜¸ ì €ì¥
                if current_item and current_lines:
                    item_text = '\n'.join(current_lines)
                    subitems = self._parse_subitems(item_text)
                    items.append({
                        'id': current_item,
                        'text': item_text,
                        'subitems': subitems
                    })
                
                current_item = match.group(1)
                current_lines = [line]
            elif current_item:
                current_lines.append(line)
        
        # ë§ˆì§€ë§‰ í˜¸ ì €ì¥
        if current_item and current_lines:
            item_text = '\n'.join(current_lines)
            subitems = self._parse_subitems(item_text)
            items.append({
                'id': current_item,
                'text': item_text,
                'subitems': subitems
            })
        
        return items
    
    def _parse_subitems(self, text: str) -> List[Dict]:
        """
        í˜¸ ë‚´ì—ì„œ ëª©(ê°€. ë‚˜. ë‹¤. ...) íŒŒì‹±
        
        Args:
            text: í˜¸ í…ìŠ¤íŠ¸
            
        Returns:
            ëª© ëª©ë¡
        """
        subitems = []
        lines = text.split('\n')
        current_sub = None
        current_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # ëª© íŒ¨í„´: "ê°€. " (í•œê¸€ ììŒ + ë§ˆì¹¨í‘œ + ê³µë°±)
            match = re.match(r'^([ê°€-í£])\.\s', line)
            if match:
                if current_sub and current_lines:
                    subitems.append({
                        'id': current_sub,
                        'text': '\n'.join(current_lines)
                    })
                
                current_sub = match.group(1)
                current_lines = [line]
            elif current_sub:
                current_lines.append(line)
        
        if current_sub and current_lines:
            subitems.append({
                'id': current_sub,
                'text': '\n'.join(current_lines)
            })
        
        return subitems


# ==========================================
# Neo4j ê·¸ë˜í”„ ë¹Œë”
# ==========================================
class GraphBuilder:
    """
    íŒŒì‹±ëœ ë²•ë ¹ ë°ì´í„°ë¥¼ Neo4j ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤
    
    ë…¸ë“œ ì¢…ë¥˜:
    - Article: ì¡°í•­
    - Clause: í•­
    - Item: í˜¸
    - Subitem: ëª©
    
    ê´€ê³„ ì¢…ë¥˜:
    - CONTAINS: í¬í•¨ ê´€ê³„ (ì¡°í•­â†’í•­, í•­â†’í˜¸, í˜¸â†’ëª©)
    - REFERS_TO: ë™ì¼ ë²•ë ¹ ë‚´ ì°¸ì¡°
    - DELEGATES_TO: ìœ„ì„ ê´€ê³„ (ë²•â†’ë ¹, ë ¹â†’ê·œì¹™)
    - CROSS_REFERS_TO: ë‹¤ë¥¸ ë²•ë ¹ ê°„ ì°¸ì¡°
    """
    
    def __init__(self, uri: str, user: str, password: str):
        """
        Neo4j ì—°ê²° ì´ˆê¸°í™”
        
        Args:
            uri: Neo4j ì„œë²„ URI
            user: ì‚¬ìš©ìëª…
            password: ë¹„ë°€ë²ˆí˜¸
        """
        # Neo4j ë“œë¼ì´ë²„ ìƒì„± (authëŠ” íŠœí”Œë¡œ ì „ë‹¬)
        self.driver = GraphDatabase.driver(
            uri, 
            auth=(user, password),
            max_connection_lifetime=3600
        )
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        try:
            self.driver.verify_connectivity()
            logger.info(f"âœ… Neo4j ì—°ê²° ì„±ê³µ: {uri}")
        except Exception as e:
            logger.error(f"âŒ Neo4j ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
    
    def close(self):
        """ë“œë¼ì´ë²„ ì—°ê²° ì¢…ë£Œ"""
        self.driver.close()
    
    def clear(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì „ì²´ ì´ˆê¸°í™” (ì£¼ì˜!)"""
        with self.driver.session() as session:
            session.run("MATCH (n) DETACH DELETE n")
        logger.info("âš ï¸  ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def create_indexes(self):
        """ê²€ìƒ‰ ì„±ëŠ¥ì„ ìœ„í•œ ì¸ë±ìŠ¤ ìƒì„±"""
        with self.driver.session() as session:
            indexes = [
                "CREATE INDEX IF NOT EXISTS FOR (a:Article) ON (a.uid)",
                "CREATE INDEX IF NOT EXISTS FOR (a:Article) ON (a.article_id)",
                "CREATE INDEX IF NOT EXISTS FOR (a:Article) ON (a.law_code)",
                "CREATE INDEX IF NOT EXISTS FOR (c:Clause) ON (c.uid)",
                "CREATE INDEX IF NOT EXISTS FOR (i:Item) ON (i.uid)",
                "CREATE INDEX IF NOT EXISTS FOR (s:Subitem) ON (s.uid)",
            ]
            for idx in indexes:
                try:
                    session.run(idx)
                except Exception:
                    pass
        logger.info("âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
    
    def build(self, data: Dict, law_def: LawDefinition):
        """
        ê·¸ë˜í”„ êµ¬ì¶• ë©”ì¸ í•¨ìˆ˜
        
        Args:
            data: íŒŒì‹±ëœ ë²•ë ¹ ë°ì´í„°
            law_def: ë²•ë ¹ ì •ì˜ ê°ì²´
        """
        law_code = data['law_code']
        law_type = data['law_type']
        
        # Neo4j ë ˆì´ë¸” ì„ íƒ
        if law_type == 'Act':
            label = law_def.act_label
        elif law_type == 'Decree':
            label = law_def.decree_label
        else:
            label = law_def.rule_label
        
        logger.info(f"ğŸ”¨ ê·¸ë˜í”„ êµ¬ì¶• ì‹œì‘: {law_code}/{law_type} ({label})")
        
        with self.driver.session() as session:
            for art in data['articles']:
                self._build_article(session, art, law_code, law_type, label)
        
        logger.info(f"âœ… ê·¸ë˜í”„ êµ¬ì¶• ì™„ë£Œ: {law_code}/{law_type}")
    
    def _build_article(self, session, art: Dict, law_code: str, law_type: str, label: str):
        """
        ì¡°í•­ ë° í•˜ìœ„ êµ¬ì¡°(í•­, í˜¸, ëª©) ë…¸ë“œ ìƒì„±
        
        Args:
            session: Neo4j ì„¸ì…˜
            art: ì¡°í•­ ë°ì´í„°
            law_code: ë²•ë ¹ ì½”ë“œ
            law_type: ë²•ë ¹ ì¢…ë¥˜
            label: Neo4j ë ˆì´ë¸”
        """
        # ì¡°í•­ ê³ ìœ  ID
        art_uid = f"{law_code}_{law_type}_{art['id']}"
        
        # ì¡°í•­ ë…¸ë“œ ìƒì„± (Article + ë²•ë ¹ë³„ ë ˆì´ë¸”)
        session.run(f"""
            MERGE (a:Article:{label} {{uid: $uid}})
            SET a.article_id = $id,
                a.title = $title,
                a.law_code = $law_code,
                a.law_type = $law_type,
                a.full_text = $text
        """, {
            'uid': art_uid,
            'id': art['id'],
            'title': art['title'],
            'law_code': law_code,
            'law_type': law_type,
            'text': art['text']
        })
        
        # í•­(Clause) ì²˜ë¦¬
        for clause in art['clauses']:
            cls_uid = f"{art_uid}_{clause['id']}"
            
            session.run("""
                MERGE (c:Clause {uid: $uid})
                SET c.clause_id = $id,
                    c.content = $text,
                    c.law_code = $law_code,
                    c.law_type = $law_type
            """, {
                'uid': cls_uid,
                'id': clause['id'],
                'text': clause['text'],
                'law_code': law_code,
                'law_type': law_type
            })
            
            # ì¡°í•­ â†’ í•­ ê´€ê³„
            session.run("""
                MATCH (a:Article {uid: $a})
                MATCH (c:Clause {uid: $c})
                MERGE (a)-[:CONTAINS]->(c)
            """, {'a': art_uid, 'c': cls_uid})
            
            # í˜¸(Item) ì²˜ë¦¬
            for item in clause['items']:
                itm_uid = f"{cls_uid}_{item['id']}"
                
                session.run("""
                    MERGE (i:Item {uid: $uid})
                    SET i.item_id = $id,
                        i.content = $text,
                        i.law_code = $law_code,
                        i.law_type = $law_type
                """, {
                    'uid': itm_uid,
                    'id': item['id'],
                    'text': item['text'],
                    'law_code': law_code,
                    'law_type': law_type
                })
                
                # í•­ â†’ í˜¸ ê´€ê³„
                session.run("""
                    MATCH (c:Clause {uid: $c})
                    MATCH (i:Item {uid: $i})
                    MERGE (c)-[:CONTAINS]->(i)
                """, {'c': cls_uid, 'i': itm_uid})
                
                # ëª©(Subitem) ì²˜ë¦¬
                for sub in item['subitems']:
                    sub_uid = f"{itm_uid}_{sub['id']}"
                    
                    session.run("""
                        MERGE (s:Subitem {uid: $uid})
                        SET s.subitem_id = $id,
                            s.content = $text,
                            s.law_code = $law_code,
                            s.law_type = $law_type
                    """, {
                        'uid': sub_uid,
                        'id': sub['id'],
                        'text': sub['text'],
                        'law_code': law_code,
                        'law_type': law_type
                    })
                    
                    # í˜¸ â†’ ëª© ê´€ê³„
                    session.run("""
                        MATCH (i:Item {uid: $i})
                        MATCH (s:Subitem {uid: $s})
                        MERGE (i)-[:CONTAINS]->(s)
                    """, {'i': itm_uid, 's': sub_uid})
    
    def create_relations(self):
        """
        ì¡°í•­ ê°„ ì°¸ì¡°/ìœ„ì„ ê´€ê³„ ìƒì„±
        
        ê´€ê³„ ì¢…ë¥˜:
        - REFERS_TO: ë™ì¼ ë²•ë ¹ ë‚´ ì°¸ì¡° (ì œNì¡° ì°¸ì¡°)
        - DELEGATES_TO: ìœ„ì„ ê´€ê³„ (ë²•â†’ì˜, ì˜â†’ê·œì¹™)
        - CROSS_REFERS_TO: ë‹¤ë¥¸ ë²•ë ¹ ê°„ ì°¸ì¡°
        """
        logger.info("ğŸ”— ê´€ê³„ ìƒì„± ì‹œì‘...")
        
        # ì •ê·œì‹ íŒ¨í„´
        p_internal = re.compile(r'ì œ(\d+(?:ì˜\d+)?)ì¡°')       # ë‚´ë¶€ ì°¸ì¡°
        p_act_ref = re.compile(r'ë²•\s*ì œ(\d+(?:ì˜\d+)?)ì¡°')   # ì‹œí–‰ë ¹ì—ì„œ ë²• ì°¸ì¡°
        p_decree_ref = re.compile(r'ì˜\s*ì œ(\d+(?:ì˜\d+)?)ì¡°') # ì‹œí–‰ê·œì¹™ì—ì„œ ì‹œí–‰ë ¹ ì°¸ì¡°
        
        with self.driver.session() as session:
            # ëª¨ë“  ì¡°í•­ ê°€ì ¸ì˜¤ê¸°
            result = session.run("""
                MATCH (a:Article)
                RETURN a.uid as uid, a.full_text as text, 
                       a.law_code as code, a.law_type as type
            """)
            
            for record in result:
                uid = record['uid']
                text = record['text'] or ""
                law_code = record['code']
                law_type = record['type']
                
                # 1) ë‚´ë¶€ ì°¸ì¡° (REFERS_TO)
                for match in p_internal.finditer(text):
                    target_id = f"ì œ{match.group(1)}ì¡°"
                    target_uid = f"{law_code}_{law_type}_{target_id}"
                    
                    # ìê¸° ìì‹  ì°¸ì¡° ì œì™¸
                    if target_uid != uid:
                        session.run("""
                            MATCH (a:Article {uid: $from})
                            MATCH (b:Article {uid: $to})
                            MERGE (a)-[:REFERS_TO]->(b)
                        """, {'from': uid, 'to': target_uid})
                
                # 2) ìœ„ì„ ê´€ê³„ (DELEGATES_TO)
                if law_type == 'Decree':
                    # ì‹œí–‰ë ¹ â†’ ë²•ë¥  ì°¸ì¡°
                    for match in p_act_ref.finditer(text):
                        target_id = f"ì œ{match.group(1)}ì¡°"
                        target_uid = f"{law_code}_Act_{target_id}"
                        session.run("""
                            MATCH (a:Article {uid: $from})
                            MATCH (b:Article {uid: $to})
                            MERGE (a)-[:DELEGATES_TO]->(b)
                        """, {'from': uid, 'to': target_uid})
                
                elif law_type == 'Rule':
                    # ì‹œí–‰ê·œì¹™ â†’ ì‹œí–‰ë ¹ ì°¸ì¡°
                    for match in p_decree_ref.finditer(text):
                        target_id = f"ì œ{match.group(1)}ì¡°"
                        target_uid = f"{law_code}_Decree_{target_id}"
                        session.run("""
                            MATCH (a:Article {uid: $from})
                            MATCH (b:Article {uid: $to})
                            MERGE (a)-[:DELEGATES_TO]->(b)
                        """, {'from': uid, 'to': target_uid})
        
        logger.info("âœ… ê´€ê³„ ìƒì„± ì™„ë£Œ")
    
    def print_stats(self):
        """ê·¸ë˜í”„ í†µê³„ ì¶œë ¥"""
        with self.driver.session() as session:
            # ë²•ë ¹ë³„ ì¡°í•­ ìˆ˜
            law_stats = session.run("""
                MATCH (a:Article)
                RETURN a.law_code as law, a.law_type as type, count(a) as cnt
                ORDER BY a.law_code, a.law_type
            """).data()
            
            # ì „ì²´ ë…¸ë“œ ìˆ˜
            total_articles = session.run("MATCH (a:Article) RETURN count(a)").single()[0]
            total_clauses = session.run("MATCH (c:Clause) RETURN count(c)").single()[0]
            total_items = session.run("MATCH (i:Item) RETURN count(i)").single()[0]
            total_subitems = session.run("MATCH (s:Subitem) RETURN count(s)").single()[0]
            
            # ê´€ê³„ ìˆ˜
            contains = session.run("MATCH ()-[r:CONTAINS]->() RETURN count(r)").single()[0]
            refers = session.run("MATCH ()-[r:REFERS_TO]->() RETURN count(r)").single()[0]
            delegates = session.run("MATCH ()-[r:DELEGATES_TO]->() RETURN count(r)").single()[0]
            
            # í†µê³„ ì¶œë ¥
            msg = []
            msg.append("\n" + "="*70)
            msg.append("ğŸ“Š Knowledge Graph í†µê³„")
            msg.append("="*70)
            
            msg.append("\n[ë²•ë ¹ë³„ ì¡°í•­ ìˆ˜]")
            current_law = None
            for stat in law_stats:
                if stat['law'] != current_law:
                    if current_law:
                        msg.append("")
                    current_law = stat['law']
                    law_name = LAWS.get(stat['law'], LawDefinition(code=stat['law'], name=stat['law'], 
                                        act_label='', decree_label='', rule_label='', pdf_paths={})).name
                    msg.append(f"\n{law_name}")
                msg.append(f"  {stat['type']:8s}: {stat['cnt']:4d}ê°œ")
            
            msg.append(f"\n\n[ì „ì²´ ë…¸ë“œ]")
            msg.append(f"  Article  : {total_articles:,}")
            msg.append(f"  Clause   : {total_clauses:,}")
            msg.append(f"  Item     : {total_items:,}")
            msg.append(f"  Subitem  : {total_subitems:,}")
            msg.append(f"  í•©ê³„     : {total_articles+total_clauses+total_items+total_subitems:,}")
            
            msg.append(f"\n[ê´€ê³„]")
            msg.append(f"  CONTAINS    : {contains:,}")
            msg.append(f"  REFERS_TO   : {refers:,}")
            msg.append(f"  DELEGATES_TO: {delegates:,}")
            msg.append(f"  í•©ê³„        : {contains+refers+delegates:,}")
            msg.append("="*70 + "\n")
            
            logger.info('\n'.join(msg))


# ==========================================
# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ í•¨ìˆ˜
# ==========================================
def load_env_file(env_path: str = ".env") -> Dict[str, str]:
    """
    .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ë¥¼ ì½ì–´ì˜¤ëŠ” í•¨ìˆ˜
    
    Args:
        env_path: .env íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ .env)
        
    Returns:
        í™˜ê²½ë³€ìˆ˜ ë”•ì…”ë„ˆë¦¬
    """
    env_vars = {}
    
    if not os.path.exists(env_path):
        logger.warning(f"âš ï¸  .env íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {env_path}")
        return env_vars
    
    with open(env_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            
            # ë¹ˆ ì¤„ì´ë‚˜ ì£¼ì„ ë¬´ì‹œ
            if not line or line.startswith('#'):
                continue
            
            # KEY=VALUE í˜•ì‹ íŒŒì‹±
            if '=' in line:
                key, value = line.split('=', 1)
                key = key.strip()
                value = value.strip()
                
                # ë”°ì˜´í‘œ ì œê±° (ì‹œì‘ê³¼ ëì´ ê°™ì€ ë”°ì˜´í‘œì¸ ê²½ìš°)
                if (value.startswith('"') and value.endswith('"')) or \
                   (value.startswith("'") and value.endswith("'")):
                    value = value[1:-1]
                
                env_vars[key] = value
                # í™˜ê²½ë³€ìˆ˜ë¡œë„ ì„¤ì •
                os.environ[key] = value
    
    logger.info(f"âœ… .env íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(env_vars)}ê°œ ë³€ìˆ˜")
    return env_vars


# ==========================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ==========================================
def main(
    law_codes: Optional[List[str]] = None,
    clear_db: bool = True,
    env_path: str = ".env"
):
    """
    Knowledge Graph êµ¬ì¶• ë©”ì¸ í•¨ìˆ˜
    
    .env íŒŒì¼ì—ì„œ ë‹¤ìŒ í™˜ê²½ë³€ìˆ˜ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤:
    - NEO4J_URI: Neo4j ì„œë²„ URI (ê¸°ë³¸ê°’: bolt://localhost:7687)
    - NEO4J_USER: Neo4j ì‚¬ìš©ìëª… (ê¸°ë³¸ê°’: neo4j)
    - NEO4J_PASSWORD: Neo4j ë¹„ë°€ë²ˆí˜¸ (í•„ìˆ˜)
    - UPSTAGE_API_KEY: Upstage API í‚¤ (í•„ìˆ˜)
    
    Args:
        law_codes: ì²˜ë¦¬í•  ë²•ë ¹ ì½”ë“œ ëª©ë¡ (Noneì´ë©´ ì „ì²´)
        clear_db: ì‹œì‘ ì „ DB ì´ˆê¸°í™” ì—¬ë¶€
        env_path: .env íŒŒì¼ ê²½ë¡œ
    """
    logger.info("="*70)
    logger.info(f"ğŸš€ ë²•ë ¹ Knowledge Graph êµ¬ì¶• ì‹œì‘")
    logger.info(f"   ì‹œê°„: {datetime.datetime.now()}")
    logger.info("="*70)
    
    # .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
    load_env_file(env_path)
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°
    neo4j_uri = os.getenv("NEO4J_URI", "bolt://localhost:7687")
    neo4j_user = os.getenv("NEO4J_USER", "neo4j")
    neo4j_password = os.getenv("NEO4J_PASSWORD")
    upstage_api_key = os.getenv("UPSTAGE_API_KEY")
    
    # í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ í™•ì¸
    if not neo4j_password:
        logger.error("âŒ NEO4J_PASSWORD í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        logger.error("   .env íŒŒì¼ì— NEO4J_PASSWORD=your_password í˜•ì‹ìœ¼ë¡œ ì¶”ê°€í•˜ì„¸ìš”.")
        return
    
    if not upstage_api_key:
        logger.error("âŒ UPSTAGE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        logger.error("   .env íŒŒì¼ì— UPSTAGE_API_KEY=your_api_key í˜•ì‹ìœ¼ë¡œ ì¶”ê°€í•˜ì„¸ìš”.")
        return
    
    logger.info(f"ğŸ“Œ Neo4j URI: {neo4j_uri}")
    logger.info(f"ğŸ“Œ Neo4j User: {neo4j_user}")
    logger.info(f"ğŸ“Œ Upstage API Key: {upstage_api_key[:8]}...")
    
    # 1. Upstage ì¶”ì¶œê¸° ì´ˆê¸°í™”
    try:
        extractor = UpstageDocumentExtractor(api_key=upstage_api_key)
    except ValueError as e:
        logger.error(f"âŒ Upstage ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    # 2. íŒŒì„œ ì´ˆê¸°í™”
    parser = LawParser()
    
    # 3. Neo4j ë¹Œë” ì´ˆê¸°í™”
    try:
        logger.info(f"ğŸ”Œ Neo4j ì—°ê²° ì‹œë„ ì¤‘... ({neo4j_uri})")
        builder = GraphBuilder(neo4j_uri, neo4j_user, neo4j_password)
    except Exception as e:
        logger.error(f"âŒ Neo4j ì—°ê²° ì‹¤íŒ¨: {e}")
        logger.error("   ë‹¤ìŒ ì‚¬í•­ì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
        logger.error("   1. Neo4j ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸")
        logger.error("   2. NEO4J_URIê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸ (ì˜ˆ: bolt://localhost:7687)")
        logger.error("   3. NEO4J_USERì™€ NEO4J_PASSWORDê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        logger.error("   4. neo4j íŒ¨í‚¤ì§€ ë²„ì „ í™•ì¸: pip install --upgrade neo4j")
        return
    
    try:
        # DB ì´ˆê¸°í™”
        # if clear_db:
        #     builder.clear()
        
        # ì¸ë±ìŠ¤ ìƒì„±
        builder.create_indexes()
        
        # ì²˜ë¦¬í•  ë²•ë ¹ ì„ íƒ
        laws_to_process = law_codes if law_codes else list(LAWS.keys())
        
        # 4. ê° ë²•ë ¹ ì²˜ë¦¬
        for law_code in laws_to_process:
            if law_code not in LAWS:
                logger.warning(f"âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” ë²•ë ¹ ì½”ë“œ: {law_code}")
                continue
            
            law_def = LAWS[law_code]
            logger.info(f"\n{'='*50}")
            logger.info(f"ğŸ“š {law_def.name} ì²˜ë¦¬ ì‹œì‘")
            logger.info(f"{'='*50}")
            
            # ë²•ë¥ , ì‹œí–‰ë ¹, ì‹œí–‰ê·œì¹™ ìˆœì„œë¡œ ì²˜ë¦¬
            for law_type, pdf_path in law_def.pdf_paths.items():
                if not os.path.exists(pdf_path):
                    logger.warning(f"âš ï¸  íŒŒì¼ ì—†ìŒ: {pdf_path}")
                    continue
                
                # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ (Upstage API ì‚¬ìš©)
                text = extractor.extract(pdf_path)
                if not text:
                    continue
                
                # ë²•ë ¹ íŒŒì‹±
                data = parser.parse(text, law_code, law_type)
                
                # ê·¸ë˜í”„ êµ¬ì¶•
                builder.build(data, law_def)
        
        # 5. ê´€ê³„ ìƒì„±
        builder.create_relations()
        
        # 6. í†µê³„ ì¶œë ¥
        builder.print_stats()
        
        logger.info("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
        
    finally:
        builder.close()


# ==========================================
# ì‹¤í–‰
# ==========================================
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='ë²•ë ¹ Knowledge Graph êµ¬ì¶• (Upstage ë²„ì „)')
    parser.add_argument('--env', default='.env', help='.env íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: .env)')
    parser.add_argument('--laws', nargs='+', default=None, help='ì²˜ë¦¬í•  ë²•ë ¹ ì½”ë“œ (ì˜ˆ: BUILDING BUILDING_MGMT)')
    parser.add_argument('--no-clear', action='store_true', help='DB ì´ˆê¸°í™” ì•ˆ í•¨')
    
    args = parser.parse_args()
    
    main(
        law_codes=args.laws,
        clear_db=not args.no_clear,
        env_path=args.env
    )