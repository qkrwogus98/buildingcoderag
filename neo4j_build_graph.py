"""
ê±´ì¶• ê´€ë ¨ ë²•ë ¹ Graph RAG - ë‹¤ì¤‘ ë²•ë ¹ ì§€ì› ë²„ì „
ê±´ì¶•ë²•, ê±´ì¶•ë¬¼ê´€ë¦¬ë²•, ì£¼íƒë²•, êµ­í† ê³„íšë²•, ì£¼ì°¨ì¥ë²•, ê±´ì¶•ì„œë¹„ìŠ¤ì‚°ì—…ì§„í¥ë²•
"""

import pdfplumber
import re
import os
from neo4j import GraphDatabase
from typing import List, Dict, Tuple
import logging
import datetime
from dataclasses import dataclass

# ê¸°ì¡´ logging ì„¤ì • ëŒ€ì‹  ì•„ë˜ í•¨ìˆ˜ë¥¼ ì‚¬ìš©
def setup_custom_logger():
    # ë¡œê±° ê°€ì ¸ì˜¤ê¸°
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ê°€ ìˆë‹¤ë©´ ì œê±° (ì¤‘ë³µ ì¶œë ¥ ë°©ì§€)
    if logger.hasHandlers():
        logger.handlers.clear()
        
    # í¬ë§·í„° ì„¤ì •
    formatter = logging.Formatter('%(levelname)s - %(message)s')
    
    # 1. ì½˜ì†” ì¶œë ¥ìš© í•¸ë“¤ëŸ¬ (StreamHandler)
    stream_handler = logging.StreamHandler()
    stream_handler.setFormatter(formatter)
    logger.addHandler(stream_handler)
    
    # 2. íŒŒì¼ ì €ì¥ìš© í•¸ë“¤ëŸ¬ (FileHandler) - mode='a' (append)
    # encoding='utf-8'ì„ ë„£ì–´ í•œê¸€ ê¹¨ì§ ë°©ì§€
    file_handler = logging.FileHandler('build_graph_log.txt', mode='a', encoding='utf-8')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    
    return logger

logger = setup_custom_logger()

# ==========================================
# ë²•ë ¹ ì •ì˜
# ==========================================
@dataclass
class LawDefinition:
    """ë²•ë ¹ ì •ì˜"""
    code: str           # ì§§ì€ ì½”ë“œ (ì˜ˆ: BUILDING, HOUSING)
    name: str           # ë²•ë ¹ëª… (ì˜ˆ: ê±´ì¶•ë²•, ì£¼íƒë²•)
    act_label: str      # Neo4j ë ˆì´ë¸” (ì˜ˆ: BuildingAct)
    decree_label: str
    rule_label: str
    pdf_paths: Dict[str, str]  # {'Act': 'path', 'Decree': 'path', 'Rule': 'path'}


# ì§€ì›í•˜ëŠ” ë²•ë ¹ ëª©ë¡
LAWS = {
    'BUILDING': LawDefinition(
        code='BUILDING',
        name='ê±´ì¶•ë²•',
        act_label='BuildingAct',
        decree_label='BuildingDecree',
        rule_label='BuildingRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/ê±´ì¶•ë²•(ë²•ë¥ )(ì œ21065í˜¸)(20251001).pdf',
            'Decree': '/home/jaehyeonpark/Downloads/ê±´ì¶•ë²• ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ35811í˜¸)(20251001).pdf',
            'Rule': '/home/jaehyeonpark/Downloads/ê±´ì¶•ë²• ì‹œí–‰ê·œì¹™(êµ­í† êµí†µë¶€ë ¹)(ì œ01531í˜¸)(20251031).pdf'
        }
    ),
    'BUILDING_MGMT': LawDefinition(
        code='BUILDING_MGMT',
        name='ê±´ì¶•ë¬¼ê´€ë¦¬ë²•',
        act_label='BuildingMgmtAct',
        decree_label='BuildingMgmtDecree',
        rule_label='BuildingMgmtRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/ê±´ì¶•ë¬¼ê´€ë¦¬ë²•(ë²•ë¥ )(ì œ20549í˜¸)(20250604).pdf',
            'Decree': '/home/jaehyeonpark/Downloads/ê±´ì¶•ë¬¼ê´€ë¦¬ë²• ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ35549í˜¸)(20250604).pdf',
            'Rule': '/home/jaehyeonpark/Downloads/ê±´ì¶•ë¬¼ê´€ë¦¬ë²• ì‹œí–‰ê·œì¹™(êµ­í† êµí†µë¶€ë ¹)(ì œ01495í˜¸)(20250602).pdf'
        }
    ),
    'BUILDING_SERVICE': LawDefinition(
        code='BUILDING_SERVICE',
        name='ê±´ì¶•ì„œë¹„ìŠ¤ì‚°ì—…ì§„í¥ë²•',
        act_label='BuildingServiceAct',
        decree_label='BuildingServiceDecree',
        rule_label='BuildingServiceRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/ê±´ì¶•ì„œë¹„ìŠ¤ì‚°ì—… ì§„í¥ë²•(ë²•ë¥ )(ì œ19990í˜¸)(20240710).pdf',
            'Decree': '/home/jaehyeonpark/Downloads/ê±´ì¶•ì„œë¹„ìŠ¤ì‚°ì—… ì§„í¥ë²• ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ33466í˜¸)(20230516).pdf',
            'Rule': '/home/jaehyeonpark/Downloads/ê±´ì¶•ì„œë¹„ìŠ¤ì‚°ì—… ì§„í¥ë²• ì‹œí–‰ê·œì¹™(êµ­í† êµí†µë¶€ë ¹)(ì œ00098í˜¸)(20140605).pdf'
        }
    ),
    'PARKING': LawDefinition(
        code='PARKING',
        name='ì£¼ì°¨ì¥ë²•',
        act_label='ParkingAct',
        decree_label='ParkingDecree',
        rule_label='ParkingRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/ì£¼ì°¨ì¥ë²•(ë²•ë¥ )(ì œ21185í˜¸)(20251202).pdf',
            'Decree': '/home/jaehyeonpark/Downloads/ì£¼ì°¨ì¥ë²• ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ35708í˜¸)(20250817).pdf',
            'Rule': '/home/jaehyeonpark/Downloads/ì£¼ì°¨ì¥ë²• ì‹œí–‰ê·œì¹™(êµ­í† êµí†µë¶€ë ¹)(ì œ01527í˜¸)(20250930).pdf'
        }
    ),
    'LAND_PLAN': LawDefinition(
        code='LAND_PLAN',
        name='êµ­í† ì˜ê³„íšë°ì´ìš©ì—ê´€í•œë²•ë¥ ',
        act_label='LandPlanAct',
        decree_label='LandPlanDecree',
        rule_label='LandPlanRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/êµ­í† ì˜ ê³„íš ë° ì´ìš©ì— ê´€í•œ ë²•ë¥ (ë²•ë¥ )(ì œ21065í˜¸)(20251001).pdf',
            'Decree': '/home/jaehyeonpark/Downloads/êµ­í† ì˜ ê³„íš ë° ì´ìš©ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ35628í˜¸)(20251002).pdf',
            'Rule': '/home/jaehyeonpark/Downloads/êµ­í† ì˜ ê³„íš ë° ì´ìš©ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ê·œì¹™(êµ­í† êµí†µë¶€ë ¹)(ì œ01338í˜¸)(20241130).pdf'
        }
    ),
    'HOUSING': LawDefinition(
        code='HOUSING',
        name='ì£¼íƒë²•',
        act_label='HousingAct',
        decree_label='HousingDecree',
        rule_label='HousingRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/ì£¼íƒë²•.pdf',
            'Decree': '/home/jaehyeonpark/Downloads/ì£¼íƒë²• ì‹œí–‰ë ¹.pdf',
            'Rule': '/home/jaehyeonpark/Downloads/ì£¼íƒë²• ì‹œí–‰ê·œì¹™.pdf'
        }
    ),
    'GREEN_BUILDING': LawDefinition(
        code='GREEN_BUILDING',
        name='ë…¹ìƒ‰ê±´ì¶•ë¬¼ì¡°ì„±ì§€ì›ë²•',
        act_label='GreenBuildingAct',
        decree_label='GreenBuildingDecree',
        rule_label='GreenBuildingRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›ë²•(ë²•ë¥ )(ì œ21065í˜¸)(20251001).pdf',
            'Decree': '/home/jaehyeonpark/Downloads/ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›ë²• ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ35811í˜¸)(20251001).pdf',
            'Rule': '/home/jaehyeonpark/Downloads/ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›ë²• ì‹œí–‰ê·œì¹™(êµ­í† êµí†µë¶€ë ¹)(ì œ01422í˜¸)(20250101).pdf'
        }
    ),
    'HANOK': LawDefinition(
        code='HANOK',
        name='í•œì˜¥ë“±ê±´ì¶•ìì‚°ì˜ì§„í¥ì—ê´€í•œë²•ë¥ ',
        act_label='HanokAct',
        decree_label='HanokDecree',
        rule_label='HanokRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/í•œì˜¥ ë“± ê±´ì¶•ìì‚°ì˜ ì§„í¥ì— ê´€í•œ ë²•ë¥ (ë²•ë¥ )(ì œ19702í˜¸)(20240915).pdf',
            'Decree': '/home/jaehyeonpark/Downloads/í•œì˜¥ ë“± ê±´ì¶•ìì‚°ì˜ ì§„í¥ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ34494í˜¸)(20240517).pdf',
            'Rule': '/home/jaehyeonpark/Downloads/í•œì˜¥ ë“± ê±´ì¶•ìì‚°ì˜ ì§„í¥ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ê·œì¹™(êµ­í† êµí†µë¶€ë ¹)(ì œ00882í˜¸)(20210827).pdf'
        }
    ),
    'BUILDING_SALE': LawDefinition(
        code='BUILDING_SALE',
        name='ê±´ì¶•ë¬¼ì˜ë¶„ì–‘ì—ê´€í•œë²•ë¥ ',
        act_label='BuildingSaleAct',
        decree_label='BuildingSaleDecree',
        rule_label='BuildingSaleRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/í•œì˜¥ ë“± ê±´ì¶•ìì‚°ì˜ ì§„í¥ì— ê´€í•œ ë²•ë¥ (ë²•ë¥ )(ì œ19702í˜¸)(20240915).pdf',
            'Decree': '/home/jaehyeonpark/Downloads/í•œì˜¥ ë“± ê±´ì¶•ìì‚°ì˜ ì§„í¥ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ34494í˜¸)(20240517).pdf',
            'Rule': '/home/jaehyeonpark/Downloads/í•œì˜¥ ë“± ê±´ì¶•ìì‚°ì˜ ì§„í¥ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ê·œì¹™(êµ­í† êµí†µë¶€ë ¹)(ì œ00882í˜¸)(20210827).pdf'
        }
    ),
    'CONVENIENCE': LawDefinition(
        code='CONVENIENCE',
        name='ì¥ì• ì¸ë…¸ì¸ì„ì‚°ë¶€ë“±ì˜í¸ì˜ì¦ì§„ë³´ì¥ì—ê´€í•œë²•ë¥ ',
        act_label='ConvenienceAct',
        decree_label='ConvenienceDecree',
        rule_label='ConvenienceRule',
        pdf_paths={
            'Act': '/home/jaehyeonpark/Downloads/ì¥ì• ì¸ã†ë…¸ì¸ã†ì„ì‚°ë¶€ ë“±ì˜ í¸ì˜ì¦ì§„ ë³´ì¥ì— ê´€í•œ ë²•ë¥ (ë²•ë¥ )(ì œ20594í˜¸)(20251221).pdf',
            'Decree': '/home/jaehyeonpark/Downloads/ì¥ì• ì¸ã†ë…¸ì¸ã†ì„ì‚°ë¶€ ë“±ì˜ í¸ì˜ì¦ì§„ ë³´ì¥ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ë ¹(ëŒ€í†µë ¹ë ¹)(ì œ35811í˜¸)(20251001).pdf',
            'Rule': '/home/jaehyeonpark/Downloads/ì¥ì• ì¸ã†ë…¸ì¸ã†ì„ì‚°ë¶€ ë“±ì˜ í¸ì˜ì¦ì§„ ë³´ì¥ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ê·œì¹™(ë³´ê±´ë³µì§€ë¶€ë ¹)(ì œ01139í˜¸)(20251221).pdf'
        }
    ),
}


# ==========================================
# PDF ì¶”ì¶œ
# ==========================================
def extract_text_from_pdf(pdf_path: str, skip_toc=True) -> str:
    """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ëª©ì°¨ ì œì™¸)"""
    if not os.path.exists(pdf_path):
        logger.warning(f"íŒŒì¼ ì—†ìŒ: {pdf_path}")
        return ""
    
    logger.info(f"ğŸ“„ {os.path.basename(pdf_path)}")
    
    def is_toc_page(text: str) -> bool:
        """ëª©ì°¨ í˜ì´ì§€ íŒë³„"""
        if not text:
            return True
        lines = text.split('\n')
        article_lines = [l for l in lines if re.match(r'^\s*ì œ\d+ì¡°', l)]
        has_clauses = bool(re.search(r'[â‘ â‘¡â‘¢â‘£â‘¤]', text))
        return len(article_lines) > 15 and not has_clauses
    
    text = ""
    skipped = 0
    
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if not page_text:
                    continue
                
                if skip_toc and is_toc_page(page_text):
                    skipped += 1
                    continue
                
                # ë…¸ì´ì¦ˆ ì œê±°
                lines = []
                for line in page_text.split('\n'):
                    line = line.strip()
                    if line in ["ë²•ì œì²˜", "êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°"] or line.endswith("ë²•"):
                        continue
                    if line.isdigit() or re.match(r'^ë²•ì œì²˜\s+\d+', line):
                        continue
                    lines.append(line)
                
                text += '\n'.join(lines) + "\n"
        
        logger.info(f"âœ… {len(text):,}ì (ëª©ì°¨ {skipped}p ì œì™¸)")
        return text
        
    except Exception as e:
        logger.error(f"PDF ì¶”ì¶œ ì‹¤íŒ¨ {pdf_path}: {e}")
        return ""


# ==========================================
# ë²•ë ¹ íŒŒì„œ
# ==========================================
class LawParser:
    """ë²•ë ¹ íŒŒì„œ"""
    
    def parse(self, text: str, law_code: str, law_type: str) -> Dict:
        """
        ë²•ë ¹ íŒŒì‹±
        
        Args:
            text: PDF í…ìŠ¤íŠ¸
            law_code: ë²•ë ¹ ì½”ë“œ (ì˜ˆ: BUILDING, HOUSING)
            law_type: ë²•ë ¹ ì¢…ë¥˜ (Act, Decree, Rule)
        
        Returns:
            íŒŒì‹±ëœ ë°ì´í„°
        """
        articles_data = []
        
        pattern = re.compile(r'\n(ì œ\d+ì¡°(?:ì˜\d+)?)\(([^)]+)\)')
        matches = list(pattern.finditer(text))
        
        for i, match in enumerate(matches):
            article_id = match.group(1)
            title = match.group(2)
            
            start = match.start()
            end = matches[i+1].start() if i+1 < len(matches) else len(text)
            article_text = text[start:end].strip()
            
            clauses = self._parse_clauses(article_text)
            
            # ë³¸ë¬¸ì´ ìˆëŠ” ì¡°í•­ë§Œ
            if clauses or len(article_text) > 100:
                articles_data.append({
                    'id': article_id,
                    'title': title,
                    'text': article_text,
                    'clauses': clauses
                })
        
        # ì¤‘ë³µ ì œê±°
        unique = {}
        for art in articles_data:
            aid = art['id']
            if aid not in unique or len(art['text']) > len(unique[aid]['text']):
                unique[aid] = art
        
        result = list(unique.values())
        logger.info(f"âœ… {law_code}-{law_type}: {len(result)}ê°œ ì¡°í•­")
        
        return {
            'law_code': law_code,
            'law_type': law_type,
            'articles': result
        }
    
    def _parse_clauses(self, text: str) -> List[Dict]:
        """í•­ íŒŒì‹±"""
        clauses = []
        parts = re.split(r'([â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©â‘ªâ‘«â‘¬â‘­â‘®â‘¯â‘°â‘±â‘²â‘³])', text)
        
        i = 0
        while i < len(parts):
            part = parts[i]
            if re.match(r'[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©â‘ªâ‘«â‘¬â‘­â‘®â‘¯â‘°â‘±â‘²â‘³]', part):
                if i + 1 < len(parts):
                    clause_text = parts[i+1].strip()
                    if clause_text:
                        items = self._parse_items(clause_text)
                        clauses.append({
                            'id': part,
                            'text': clause_text,
                            'items': items
                        })
                i += 2
            else:
                i += 1
        
        return clauses
    
    def _parse_items(self, text: str) -> List[Dict]:
        """í˜¸ íŒŒì‹±"""
        items = []
        lines = text.split('\n')
        current_item = None
        current_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            match = re.match(r'^(\d+)\.\s', line)
            if match:
                if current_item and current_lines:
                    item_text = '\n'.join(current_lines)
                    subitems = self._parse_subitems(item_text)
                    items.append({
                        'id': current_item,
                        'text': item_text,
                        'subitems': subitems
                    })
                
                current_item = match.group(1)
                current_lines = [line]
            elif current_item:
                current_lines.append(line)
        
        if current_item and current_lines:
            item_text = '\n'.join(current_lines)
            subitems = self._parse_subitems(item_text)
            items.append({
                'id': current_item,
                'text': item_text,
                'subitems': subitems
            })
        
        return items
    
    def _parse_subitems(self, text: str) -> List[Dict]:
        """ëª© íŒŒì‹±"""
        subitems = []
        lines = text.split('\n')
        current_sub = None
        current_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            match = re.match(r'^([ê°€-í£])\.\s', line)
            if match:
                if current_sub and current_lines:
                    subitems.append({
                        'id': current_sub,
                        'text': '\n'.join(current_lines)
                    })
                
                current_sub = match.group(1)
                current_lines = [line]
            elif current_sub:
                current_lines.append(line)
        
        if current_sub and current_lines:
            subitems.append({
                'id': current_sub,
                'text': '\n'.join(current_lines)
            })
        
        return subitems


# ==========================================
# Neo4j Graph Builder
# ==========================================
class GraphBuilder:
    """Neo4j ê·¸ë˜í”„ êµ¬ì¶•"""
    
    def __init__(self, uri: str, user: str, password: str):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
        logger.info(f"âœ… Neo4j ì—°ê²°")
    
    def close(self):
        self.driver.close()
    
    def clear(self):
        with self.driver.session() as session:
            session.run("MATCH (n) DETACH DELETE n")
        logger.info("âš ï¸  DB ì´ˆê¸°í™”")
    
    def create_indexes(self):
        """ì¸ë±ìŠ¤ ìƒì„±"""
        with self.driver.session() as session:
            indexes = [
                "CREATE INDEX IF NOT EXISTS FOR (a:Article) ON (a.uid)",
                "CREATE INDEX IF NOT EXISTS FOR (a:Article) ON (a.article_id)",
                "CREATE INDEX IF NOT EXISTS FOR (a:Article) ON (a.law_code)",
                "CREATE INDEX IF NOT EXISTS FOR (c:Clause) ON (c.uid)",
                "CREATE INDEX IF NOT EXISTS FOR (i:Item) ON (i.uid)",
                "CREATE INDEX IF NOT EXISTS FOR (s:Subitem) ON (s.uid)",
            ]
            for idx in indexes:
                try:
                    session.run(idx)
                except:
                    pass
        logger.info("âœ… ì¸ë±ìŠ¤")
    
    def build(self, data: Dict, law_def: LawDefinition):
        """
        ê·¸ë˜í”„ êµ¬ì¶•
        
        Args:
            data: íŒŒì‹±ëœ ë°ì´í„°
            law_def: ë²•ë ¹ ì •ì˜
        """
        law_code = data['law_code']
        law_type = data['law_type']
        
        # Neo4j ë ˆì´ë¸” ì„ íƒ
        if law_type == 'Act':
            label = law_def.act_label
        elif law_type == 'Decree':
            label = law_def.decree_label
        else:
            label = law_def.rule_label
        
        logger.info(f"ğŸ”¨ {law_code}-{law_type} ({label}) êµ¬ì¶•...")
        
        with self.driver.session() as session:
            for art in data['articles']:
                self._build_article(session, art, law_code, law_type, label)
        
        logger.info(f"âœ… {law_code}-{law_type}")
    
    def _build_article(self, session, art: Dict, law_code: str, law_type: str, label: str):
        """ì¡°í•­ ë° í•˜ìœ„ êµ¬ì¡° ìƒì„±"""
        art_uid = f"{law_code}_{law_type}_{art['id']}"
        
        # ì¡°í•­ ë…¸ë“œ (Article + ë²•ë ¹ë³„ ë ˆì´ë¸”)
        session.run(f"""
            MERGE (a:Article:{label} {{uid: $uid}})
            SET a.article_id = $id,
                a.title = $title,
                a.law_code = $law_code,
                a.law_type = $law_type,
                a.full_text = $text
        """, {
            'uid': art_uid,
            'id': art['id'],
            'title': art['title'],
            'law_code': law_code,
            'law_type': law_type,
            'text': art['text']
        })
        
        # í•­
        for clause in art['clauses']:
            cls_uid = f"{art_uid}_{clause['id']}"
            
            session.run("""
                MERGE (c:Clause {uid: $uid})
                SET c.clause_id = $id,
                    c.content = $text,
                    c.law_code = $law_code,
                    c.law_type = $law_type
            """, {
                'uid': cls_uid,
                'id': clause['id'],
                'text': clause['text'],
                'law_code': law_code,
                'law_type': law_type
            })
            
            session.run("""
                MATCH (a:Article {uid: $a})
                MATCH (c:Clause {uid: $c})
                MERGE (a)-[:CONTAINS]->(c)
            """, {'a': art_uid, 'c': cls_uid})
            
            # í˜¸
            for item in clause['items']:
                itm_uid = f"{cls_uid}_{item['id']}"
                
                session.run("""
                    MERGE (i:Item {uid: $uid})
                    SET i.item_id = $id,
                        i.content = $text,
                        i.law_code = $law_code,
                        i.law_type = $law_type
                """, {
                    'uid': itm_uid,
                    'id': item['id'],
                    'text': item['text'],
                    'law_code': law_code,
                    'law_type': law_type
                })
                
                session.run("""
                    MATCH (c:Clause {uid: $c})
                    MATCH (i:Item {uid: $i})
                    MERGE (c)-[:CONTAINS]->(i)
                """, {'c': cls_uid, 'i': itm_uid})
                
                # ëª©
                for sub in item['subitems']:
                    sub_uid = f"{itm_uid}_{sub['id']}"
                    
                    session.run("""
                        MERGE (s:Subitem {uid: $uid})
                        SET s.subitem_id = $id,
                            s.content = $text,
                            s.law_code = $law_code,
                            s.law_type = $law_type
                    """, {
                        'uid': sub_uid,
                        'id': sub['id'],
                        'text': sub['text'],
                        'law_code': law_code,
                        'law_type': law_type
                    })
                    
                    session.run("""
                        MATCH (i:Item {uid: $i})
                        MATCH (s:Subitem {uid: $s})
                        MERGE (i)-[:CONTAINS]->(s)
                    """, {'i': itm_uid, 's': sub_uid})
    
    def create_relations(self):
        """ì¡°í•­ ê°„ ê´€ê³„ ìƒì„± (Python ì •ê·œì‹ ê¸°ë°˜ ê°œì„  ë²„ì „)"""
        logger.info("ğŸ”— ê´€ê³„ ìƒì„±...")
        
        # ì •ê·œì‹ íŒ¨í„´ ì»´íŒŒì¼
        # 1. ë‚´ë¶€ ì°¸ì¡°: "ì œNì¡°" ë˜ëŠ” "ì œNì¡°ì˜N"
        p_internal = re.compile(r'ì œ(\d+(?:ì˜\d+)?)ì¡°')
        
        # 2. ìœ„ì„ ê´€ê³„ (ë²•/ì˜): "ë²• ì œNì¡°", "ì˜ ì œNì¡°" (ë„ì–´ì“°ê¸° í¬í•¨)
        p_act_ref = re.compile(r'ë²•\s*ì œ(\d+(?:ì˜\d+)?)ì¡°')    # ë ¹ -> ë²•
        p_decree_ref = re.compile(r'ì˜\s*ì œ(\d+(?:ì˜\d+)?)ì¡°') # ê·œì¹™ -> ë ¹
        
        # 3. ì™¸ë¶€ ë²•ë ¹ ì°¸ì¡°: "ë²•ë ¹ëª… + (ê³µë°±) + ì œNì¡°" í˜•íƒœë§Œ ì—„ê²©í•˜ê²Œ ë§¤ì¹­
        # ì˜ˆ: "ê±´ì¶•ë¬¼ê´€ë¦¬ë²• ì œ39ì¡°" (O), "ê±´ì¶•ë¬¼ê´€ë¦¬ë²• ... ì œ39ì¡°" (X - ì˜¤íƒì§€ ë°©ì§€)
        cross_patterns = {
            'BUILDING': [
                ('ì£¼íƒë²•', 'HOUSING'),
                ('ê±´ì¶•ë¬¼ê´€ë¦¬ë²•', 'BUILDING_MGMT'),
                ('êµ­í† ì˜ê³„íšë°ì´ìš©ì—ê´€í•œë²•ë¥ ', 'LAND_PLAN'),
                ('ì£¼ì°¨ì¥ë²•', 'PARKING')
            ],
            'HOUSING': [('ê±´ì¶•ë²•', 'BUILDING')],
            'LAND_PLAN': [('ê±´ì¶•ë²•', 'BUILDING')]
        }

        with self.driver.session() as session:
            # ëª¨ë“  Articleì„ ë©”ëª¨ë¦¬ë¡œ ê°€ì ¸ì™€ì„œ ì²˜ë¦¬ (ì†ë„ ë° ì •í™•ì„± í–¥ìƒ)
            result = session.run("""
                MATCH (a:Article) 
                RETURN a.uid as uid, a.law_code as law_code, a.law_type as law_type, 
                       a.article_id as article_id, a.full_text as text
            """)
            
            articles = [record for record in result]
            total = len(articles)
            logger.info(f"ğŸ” ì´ {total}ê°œ ì¡°í•­ ë¶„ì„ ì‹œì‘...")

            rels_internal = []
            rels_delegates = []
            rels_cross = []

            for idx, r in enumerate(articles):
                uid = r['uid']
                text = r['text']
                curr_code = r['law_code']
                curr_type = r['law_type']
                curr_id = r['article_id'] # ì˜ˆ: ì œ1ì¡°

                # 1. ê°™ì€ ë²•ë ¹ ë‚´ ì°¸ì¡° (REFERS_TO)
                # "ì œ5ì¡°ì— ë”°ë¼" -> "ì œ5ì¡°" ì¶”ì¶œ
                for match in p_internal.finditer(text):
                    ref_num = match.group(1)
                    ref_id = f"ì œ{ref_num}ì¡°"
                    
                    # ìê¸° ìì‹  ì°¸ì¡° ì œì™¸
                    if ref_id != curr_id:
                        rels_internal.append({
                            'from': uid,
                            'to_code': curr_code,
                            'to_type': curr_type,
                            'to_id': ref_id
                        })

                # 2. ìœ„ì„ ê´€ê³„ (DELEGATES_TO)
                # Decree(ì‹œí–‰ë ¹) -> Act(ë²•) : "ë²• ì œXì¡°"
                if curr_type == 'Decree':
                    for match in p_act_ref.finditer(text):
                        ref_num = match.group(1)
                        rels_delegates.append({
                            'from': uid,
                            'to_code': curr_code,
                            'to_type': 'Act',
                            'to_id': f"ì œ{ref_num}ì¡°"
                        })
                
                # Rule(ì‹œí–‰ê·œì¹™) -> Decree(ì‹œí–‰ë ¹) : "ì˜ ì œXì¡°"
                elif curr_type == 'Rule':
                    for match in p_decree_ref.finditer(text):
                        ref_num = match.group(1)
                        rels_delegates.append({
                            'from': uid,
                            'to_code': curr_code,
                            'to_type': 'Decree',
                            'to_id': f"ì œ{ref_num}ì¡°"
                        })

                # 3. íƒ€ ë²•ë ¹ ì°¸ì¡° (CROSS_REFERS_TO)
                if curr_code in cross_patterns:
                    for kw, target_code in cross_patterns[curr_code]:
                        # ì •í™•íˆ "ë²•ë ¹ëª… ì œNì¡°" íŒ¨í„´ì¸ ê²½ìš°ë§Œ ì°¾ìŒ
                        # ì˜ˆ: r"ê±´ì¶•ë¬¼ê´€ë¦¬ë²•\s+ì œ(\d+)ì¡°"
                        p_cross = re.compile(re.escape(kw) + r'\s*ì œ(\d+(?:ì˜\d+)?)ì¡°')
                        for match in p_cross.finditer(text):
                            ref_num = match.group(1)
                            rels_cross.append({
                                'from': uid,
                                'to_code': target_code,
                                'to_id': f"ì œ{ref_num}ì¡°"
                            })

            # ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
            def batch_run(query, data_list, batch_size=1000):
                if not data_list: return
                for i in range(0, len(data_list), batch_size):
                    batch = data_list[i:i+batch_size]
                    session.run(query, {'batch': batch})

            # 1. REFERS_TO ì €ì¥
            logger.info(f"ğŸ’¾ REFERS_TO {len(rels_internal)}ê°œ ì €ì¥ ì¤‘...")
            q_internal = """
                UNWIND $batch as row
                MATCH (a:Article {uid: row.from})
                MATCH (t:Article {law_code: row.to_code, law_type: row.to_type, article_id: row.to_id})
                MERGE (a)-[:REFERS_TO]->(t)
            """
            batch_run(q_internal, rels_internal)

            # 2. DELEGATES_TO ì €ì¥
            logger.info(f"ğŸ’¾ DELEGATES_TO {len(rels_delegates)}ê°œ ì €ì¥ ì¤‘...")
            q_delegates = """
                UNWIND $batch as row
                MATCH (a:Article {uid: row.from})
                MATCH (t:Article {law_code: row.to_code, law_type: row.to_type, article_id: row.to_id})
                MERGE (a)-[:DELEGATES_TO]->(t)
            """
            batch_run(q_delegates, rels_delegates)

            # 3. CROSS_REFERS_TO ì €ì¥
            logger.info(f"ğŸ’¾ CROSS_REFERS_TO {len(rels_cross)}ê°œ ì €ì¥ ì¤‘...")
            q_cross = """
                UNWIND $batch as row
                MATCH (a:Article {uid: row.from})
                # íƒ€ ë²•ë ¹ì€ Act(ë²•ë¥ )ë¥¼ ì°¸ì¡°í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì´ë¯€ë¡œ law_type: 'Act'ë¡œ ê³ ì •í•˜ê±°ë‚˜ í•„ìš”ì‹œ ìˆ˜ì •
                MATCH (t:Article {law_code: row.to_code, law_type: 'Act', article_id: row.to_id})
                MERGE (a)-[:CROSS_REFERS_TO]->(t)
            """
            batch_run(q_cross, rels_cross)

        logger.info("âœ… ê´€ê³„ ìƒì„± ì™„ë£Œ")
    
    def stats(self):
        """í†µê³„ ì¶œë ¥"""
        with self.driver.session() as session:
            # ë²•ë ¹ë³„ í†µê³„
            law_stats = session.run("""
                MATCH (a:Article)
                RETURN a.law_code as law, a.law_type as type, count(a) as cnt
                ORDER BY law, type
            """).data()
            
            total_articles = session.run("MATCH (a:Article) RETURN count(a)").single()[0]
            total_clauses = session.run("MATCH (c:Clause) RETURN count(c)").single()[0]
            total_items = session.run("MATCH (i:Item) RETURN count(i)").single()[0]
            total_subitems = session.run("MATCH (s:Subitem) RETURN count(s)").single()[0]
            
            contains = session.run("MATCH ()-[r:CONTAINS]->() RETURN count(r)").single()[0]
            refers = session.run("MATCH ()-[r:REFERS_TO]->() RETURN count(r)").single()[0]
            delegates = session.run("MATCH ()-[r:DELEGATES_TO]->() RETURN count(r)").single()[0]
            cross_refers = session.run("MATCH ()-[r:CROSS_REFERS_TO]->() RETURN count(r)").single()[0]
            
            # ë¡œê·¸ ë©”ì‹œì§€ êµ¬ì„±
            msg = []
            msg.append("\n" + "="*70)
            msg.append("ğŸ“Š Graph Database í†µê³„")
            msg.append("="*70)
            
            msg.append("\n[ë²•ë ¹ë³„ ì¡°í•­ ìˆ˜]")
            current_law = None
            for stat in law_stats:
                if stat['law'] != current_law:
                    if current_law:
                        msg.append("")
                    current_law = stat['law']
                    msg.append(f"\n{LAWS[stat['law']].name}")
                msg.append(f"  {stat['type']:8s}: {stat['cnt']:4d}ê°œ")
            
            msg.append(f"\n\nì „ì²´ ë…¸ë“œ:")
            msg.append(f"  Article  : {total_articles:,}")
            msg.append(f"  Clause   : {total_clauses:,}")
            msg.append(f"  Item     : {total_items:,}")
            msg.append(f"  Subitem  : {total_subitems:,}")
            msg.append(f"  í•©ê³„     : {total_articles+total_clauses+total_items+total_subitems:,}")
            
            msg.append(f"\n[ê´€ê³„:]")
            msg.append(f"  CONTAINS       : {contains:,}")
            msg.append(f"  REFERS_TO      : {refers:,}")
            msg.append(f"  DELEGATES_TO   : {delegates:,}")
            msg.append(f"  CROSS_REFERS_TO: {cross_refers:,}")
            msg.append(f"  í•©ê³„           : {contains+refers+delegates+cross_refers:,}")
            msg.append("="*70 + "\n")


            logger.info('\n'.join(msg))


# ==========================================
# ë©”ì¸ ì‹¤í–‰
# ==========================================
def main():
    """ë©”ì¸ ì‹¤í–‰"""
    # ì‹¤í–‰ ì‹œê° ê¸°ë¡ (ë¡œê·¸ íŒŒì¼ êµ¬ë¶„ìš©)
    now_str = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    logger.info(f"\n\n{'#'*70}")
    logger.info(f"ğŸš€ ì‹¤í–‰ ì‹œì‘: {now_str}")
    logger.info(f"{'#'*70}\n")

    # Neo4j ì„¤ì •
    NEO4J_URI = "bolt://localhost:7687"
    NEO4J_USER = "neo4j"
    NEO4J_PASSWORD = "DxI3O9BGnjGjdgu800HRd8kewNhHU9URb6lCMn3V4XI"
    
    # ì²˜ë¦¬í•  ë²•ë ¹ ì„ íƒ, í•„ìš”ì‹œ ìˆ˜ì •
    # ìš°ì„ ì€ 2ê°œ ë²•ë ¹ë§Œ ì²˜ë¦¬
    laws_to_process = ['BUILDING', 'BUILDING_MGMT', 'BUILDING_SERVICE', 'PARKING', 'LAND_PLAN', 'HOUSING', 'GREEN_BUILDING',
'HANOK', 'BUILDING_SALE', 'CONVENIENCE']

    
    parser = LawParser()
    builder = GraphBuilder(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)
    
    try:
        # builder.clear()  # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì„ íƒ)
        builder.create_indexes()
        
        # ê° ë²•ë ¹ ì²˜ë¦¬
        for law_code in laws_to_process:
            law_def = LAWS[law_code]
            
            logger.info(f"\n{'='*70}")
            logger.info(f"{law_def.name} ì²˜ë¦¬")
            logger.info(f"{'='*70}")
            
            # ë²•/ë ¹/ê·œì¹™ ê°ê° ì²˜ë¦¬
            for law_type, pdf_path in law_def.pdf_paths.items():
                if not os.path.exists(pdf_path):
                    logger.warning(f"âš ï¸  íŒŒì¼ ì—†ìŒ: {pdf_path}")
                    continue
                
                text = extract_text_from_pdf(pdf_path, skip_toc=True)
                if text:
                    parsed = parser.parse(text, law_code, law_type)
                    builder.build(parsed, law_def)
        
        # ê´€ê³„ ìƒì„±
        logger.info(f"\n{'='*70}")
        builder.create_relations()
        
        # í†µê³„
        builder.stats()
        
        logger.info("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
        
    except Exception as e:
        logger.error(f"âŒ {e}", exc_info=True)
    finally:
        builder.close()


if __name__ == "__main__":
    main()